##### author 玛丽莲梦明

##### 1.Flume介绍
    1.Flume是一个分布式,可靠,高可用的海量日志采集,聚合传输的系统
    2.Flume可以采集文件,Socket数据包等各种形式源数据,又可以采集到的数据传输到HDFS,hbase,hive,kafka,等众多外部存储系统中
    3.一般采集需求,通过Flume的简单配置即可完成
    4.Flume针对特殊场景也具备良好的自定义扩展能力,因此Flume可以适用于大部分的日常数据

##### 2.Flume功能简介
    1.Flume是一款大数据中海量数据采集传输汇总的软件,特别指数据的流转过程或者说把数据从一个存储介质通过Flume传递到另一个介质
    2.核心组件
        2.1 source 用于对接各个不同的数据源
        2.2 sink 用于对接各个不同存储数据的目的地(数据的下沉地)
        2.3 channel 用于中间临时存储缓存数据


##### 3.运行机制
    Flume本身是Java程序,在需要采集数据的机器上启动 --> agent进行
    agent进程包含了Flume的三个组件 source sink channel
    在Flume中数据被包装成event 真实的数据时放在event body中
    event是Flume中最小的数据单元

##### 4.运行架构
    简单架构
    只需要部署一个agent进程即可

    复杂架构
    多个agent之间的串联,相当于大家手拉手共同完成数据的采集工作,在串联的架构中没有主从之分,大家的地位都是一样的

##### 5.flume脚本文件conf字段解释
    roll控制写入hdfs文件 以何种方式进行滚动,如果三个都配置,谁先满足谁触发滚动,如果不想以某种属性滚动设置为0即可

    a1.sinks.k1.hdfs.rollInterval = 3  以时间间隔
    a1.sinks.k1.hdfs.rollSize = 20     以文件大小(这里的20是字节,
    大数据平台Hdfs文件系统一般会以128M作为一个Block块,所以这个值可以设置为134217728)
    a1.sinks.k1.hdfs.rollCount = 5     以event个数

##### 6.是否开启时间上的舍弃,控制文件夹以多少时间间隔滚动
    a1.sinks.k1.hdfs.round = true
    a1.sinks.k1.hdfs.roundValue = 10 (就会每10分钟生成一个文件夹,不管上述滚动条件是否满足,10分钟内没有数据进入,就会生成文件)
    a1.sinks.k1.hdfs.roundUnit = minute

##### 7.spooldir source
    注意其监控的文件夹下面不能有同名文件的产生
    如果有,报错且罢工,后续就不再进行数据的监视采集了
    通常给文件追加时间戳命名的方式保证文件不会重名