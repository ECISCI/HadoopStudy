##### author Ming

##### HDFS原理
##### 一条元数据15Byte一亿条数据大概为15GB

##### 1.hdfs是什么
    Hadoop分布式文件系统(HDFS) 被设计成适合运行在通用硬件上的分布式文件系统
        1.HDFS 是一个高容错性的系统,适合部署在廉价的机器上
        2.HDFS 提供高吞吐量的数据访问,非常适合大规模数据集上的应用
        3.HDFS 放宽了一部分 posix约束,来实现流式读取文件系统数据的目的
        4.HDFS 在最开始是作为apache Nutch搜索引擎项目的基础框架而开发的
        5.HDFS 是apache hadoop core项目的一部分

##### 2.hdfs三个重要组件 NameNode DataNode SecondaryNameNode
1.Namenode
    1.1 NameNode上保存着HDFS的名字空间
    1.2 对任何文件系统元数据产生修改的操作,NameNode都会使用一种称为EditLog的是我日志记录下来
    1.3 Namenode在本地操作系统的文件系统中存储这个EditLog
    1.4 整个文件系统的名字空间,包括数据块到文件的映射,文件属性等 都存储在一个称为fsimage的文件中,这个文件也放在Namenode所在的本地文件系统上
    1.5 NameNode在内存中保存着整个文件系统的名字空间和文件数据块映射(blockmap)的映像(一个4G的内存足够支撑大量的文件和目录)
    1.6 NameNode启动时 从硬盘中读取EditLog和fsimage将所有EditLog中的事务作用在内存中的fsimage上, 并将这个新版本的fsimage从内存中保存到本地磁盘,
        然后删除旧的EditLog,这个过程称为检点(checkpoint),在当前实现中,检点只发生在NameNode启动时
    1.7 NameNode负责维护文件系统命名空间,任何文件系统名字空间属性的修改,都将被Namenode记录下来
        应用程序可以设置HDFS保存的文件的副本数目,文件副本数目成为文件副本系数,这个信息是由Namenode来保存

##### 3.hdfs DataNode
    DataNode 将hdfs数据以文件的形式存储在本地文件系统中,它并不知道有关hdfs文件的信息,它把每个HDFS数据块存储在本地文件系统的一个单独的文件中
    DataNode 并不在同一个目录创建所有的文件,实际上它用试探的方法来确定每个目录的最佳文件数目,并且在适当的时候创建子目录
    在同一个目录中创建所有的本地文件并不是最优的选择,这是因为本地文件系统可能无法高校地在单个目录中支持大量的文件
    当一个Datanode启动时,它会扫描本地文件系统,产生一个这些本地文件对应的所有HDFS数据块的列表,然后作为报告发送到NameNode这个报告就是块状态

##### 4.hdfs SecondNamenode
    4.1.NameNode响应SecondNamenode请求,将editLog推送给SecondNameNode,开始冲洗写一个新的EditLog
    4.2.SecondaryNameNode收到来自NameNode的 fsimage文件和editLog
    4.3.SNode 将fsimage加载到内存中,应用EditLog,并生成一个新的fsimage文件
    4.4.SNode将新的fsimage 推送给Namenode
    4.5.NameNode 用新的fsimage取代旧的fsimage并在fstime文件中记下检点发生时间

##### 5.HDFS通信协议

    所有HDFS通信协议都是构建在TCP/IP协议上
    客户端通过一个可配置的端口连接到Namenode通过ClientProtocol与NameNode交互
    而DataNode是使用DataNodeProtocol与Namenode交互
    在设计上Dnode通过周期性的向Nnode发送心跳和数据块来保持和Namenode的通信
    数据块报告的信息包括数据块的属性(既数据块属于哪个文件)
    数据块ID,数据块修改时间,Nnode的Dnode和数据块的映射关系就是通过系统启动时Dnode的数据块报告建立的
    从clientProtocol和DataNodeProtocol抽象出一个远程过程调用(RPC)
    在设计上,Nnode不会主动发起RPC,而是响应来自客户端和Dnode的RPC请求

##### 6.Hdfs工作机制 概述
    6.1.Hdfs分为两大角色,Namenode,Datanode(Secondary Namenode)
    6.2.Namenode负责管理整个文件系统的元数据
    6.3.Datanode负责管理用户的文件数据块
    6.4.文件会按照固定的大小(blockSize)切成若干后分布式存储在若干台datanode上
    6.5.每一个文件块可以有多个副本,并存放在不同的datanode上
    6.6.Datanode会定期向namenode汇报自身所保存的文件block信息,而namenode,则会负责保持文件副本数量
    6.7.Hdfs的内部工作机制对客户端保持透明,客户端请求访问Hdfs都是通过namenode申请来进行

##### 7.上传时,datanode的选择策略
    7.1.第一个副本优先考虑client最近的(随机架)
    7.2.第二个副本在考虑跨机架挑选一个datanode,增加副本的可靠性
    7.3.第三个副本就在第一个副本同机架挑选一台datanode存放

